% camiregu 2024-jan-30
\chapter{Constraint Problems}

%----------------------------------------------------------------------------------------

\begin{theorem}[Lagrange multipliers for $m$ constraints]
    Let $f, g_1, g_2, \dots, g_m: \Omega \to \R$ be $C^1$ functions where $\Omega \subseteq \R^{n+m} = \R^n \times \R^m$ is open and let $S = \set{x \in \Omega: g_1\of{x} = c_1, g_2\of{x} = c_2, \dots, g_m\of{x} = c_m}$ (with $c_1, c_2, \dots, c_m \in \R$). If $f$ attains an extreme value at some $s \in S$ where $\grad g_1\of{s}, \dots, \grad g_m \of{s}$ are linearly independent then there exists $\lambda_1, \lambda_2, \dots, \lambda_m \in \R$ (called Lagrange multipliers) such that $\grad f = \lambda_1 \grad g_1\of{s} + \lambda_2 \grad g_2\of{s} + \cdots + \lambda_m \grad g_m\of{s}$.
\end{theorem}
\begin{proof}
    Let $g = (g_1, \dots, g_m): \Omega \to \R^m$. Since $\grad g_1\of{s}, \dots, \grad g_m\of{s}$ are linearly independent, the matrix $D_g\of{s} = \left[\prdr{g_i}{x_j}\of{s}\right]^{m, m+n}_{i=1, j=1}$ has $m$ linearly independent rows, so also $m$ linearly independent columns. Let us consider the case that columns $n + 1, n + 2, \dots, n + m$ are linearly independent.

    Write $(x,y)$ for the elements of $\R^{n+m} = \R^n \times \R^m$ and let $a = (s_1, \dots, s_n), b = (s_{n+1}, \dots, s_{n+m}), c = (c_1, \dots, c_m)$. Clearly, $g\of{a,b} = c$, and with the notation used in the IPFT, $\prdr{g}{y}\of{a,b} = \left[\prdr{g_i}{x_j}\of{a,b}\right]^{m, n+m}_{i=1,j=n+1}$, so $\det\of{\prdr{g}{y}\of{a,b}} \neq 0$. Therefore by the IPFT there exists open sets $U \subseteq \R^n, V \subseteq \R^m$ such that $s = (a,b)$ such that $U \times V$ and a $C^1$ function $\varphi: U \to V$ such that $\varphi\of{a} = b$ and $g\of{x, \varphi\of{x}} = c$ (i.e., $(x, \varphi\of{x}) \in S$) for all $x \in U$.

    Define $\tilde{f}: U \to \R$ by $\tilde{f}\of{x} = f\of{x, \varphi\of{x}}$. Clearly, $\tilde{f}$ is a $C^1$ function and it has an extremum at $a$, so $D_{\tilde{f}}\of{a} = 0 = \grad \tilde{f}\of{a}$. Using the Chain Rule and the implicit differentiation formula for $\varphi$, we obtain:

    \[0 = D_{\tilde{f}}\of{a} = D_f\of{s} \begin{bmatrix} I_n \\ D_\varphi\of{a} \end{bmatrix} =\]
    \[= \begin{bmatrix} \prdr{f}{x}\of{s} & \prdr{f}{y}\of{s} \end{bmatrix} \begin{bmatrix} I_n \\ D_\varphi\of{a} \end{bmatrix} =\]
    \[= \prdr{f}{x}\of{s} + \prdr{f}{y}\of{s} D_\varphi\of{a} = \prdr{f}{x}\of{s} - \prdr{f}{y}\of{s} \left(\prdr{g}{y}\of{s}\right)\inv \prdr{g}{x}\of{s}\]

    i.e.,

    \[\prdr{f}{x}\of{s} = \left(\prdr{f}{y}\of{s} \left(\prdr{g}{y}\of{s}\right)\inv\right) \prdr{g}{x}\of{s}\]

    Hence, with $\prdr{f}{y}\of{s} \left(\prdr{g}{y}\of{s}\right)\inv = \left[\lambda_1, \lambda_2, \dots, \lambda_m\right]$,

    \[\prdr{f}{x_i}\of{s} = \sum_{j=1}^{m} \lambda_j \prdr{g_j}{x_i}\of{s} \forall i = 1, 2, \dots, n.\]

    But this equality also holds for $i = n+1, \dots, n + m$. Indeed,

    \[\sum_{j=1}^{m} \lambda_j \prdr{g_j}{x_i}\of{s} = \sum_{j=1}^{m} \lambda_j \prdr{g_j}{y_{i-m}}\of{s} = \begin{bmatrix} \prdr{f}{y}\of{s} \left(\prdr{g}{y}\of{s}\right)\inv \prdr{g}{y}\of{s} \end{bmatrix} =\]
    \[= \begin{bmatrix} \prdr{f}{y}\of{s} I_m \end{bmatrix} = \prdr{f}{y_{i-m}}\of{s} = \prdr{f}{x_i}\of{s}.\]

    Therefore $\grad f\of{s} = \sum_{j=1}^{m} \lambda_j \grad g_j\of{s}$.
\end{proof}

\begin{example}[two constraints]
    THe planes $x + z = 4$ and $3x - y = 6$ intersect in a line $L$. Use the Lagrange multipliers to find a point on the line $L$ that is closest to the origin.

    From geometry the minimum distance exists (and no maximum exists). We will minimize the square of the distance from the origin to a point $(x,y,z)$ on $L$.

    Let $f, g_1, g_2: \R^3 \to \R$ be given by $f\of{x,y,z} = x^2 + y^2 + z^2, g_1\of{x,y,z} = x + z, g_2\of{x,y,z} = 3x - y$. We look for the minimum of $f \restr L$, where $L = \set{(x,y,z): g_1\of{x,y,z} = 4, g_2\of{x,y,z} = 6}$. We have

    \[\grad f\of{x,y,z} = (2x, 2y, 2z), \grad g_1\of{x,y,z} = (1,0,1), \grad g_2\of{x,y,z} = (3,-1,0).\]

    Clearly, $\grad g_1\of{x,y,z}$ and $\grad g_2\of{x,y,z}$ are linearly independent for all $(x,y,z) \in R^3$. So the minimum occurs when $\grad f\of{x,y,z} = \lambda_1 \grad g_1\of{x,y,z} + \lambda_2 \grad g_2\of{x,y,z}$ for some $\lambda_1, \lambda_2 \in \R$ and we need to solve the system:
    \[ \begin{matrix}
        2x = \lambda-1 + 3\lambda_2
        \\ 2y = -\lambda_2
        \\ 2z =  \lambda_1
        \\ x + z = 4
        \\ 3x - y = 6
    \end{matrix} \implies 2x = 2z - 6y \implies x + 3y - z = 0\]

    Solving the system, we get $(x,y,z) = (2,0,2)$.

    So the nearest point on $L$ to the origin is $(2,0,2)$ and the minimum distance is $\sqrt{8} = 2\sqrt{2}$.
\end{example}

\begin{remark}
    When doing the method of Lagrange multipliers, it is important to investigate the points where the gradients are linearly dependent separately.
\end{remark}

\section{Rectangles and Partitions}

\begin{remark}
    The regular method for computing the integral in $\R$ is by way of the antiderivative. But there is no analogue to the antiderivative in $\R^n$, so our method for finding the integral will also not be analogous to how it was in $\R$.
\end{remark}

\begin{definition}[a rectangle]
    A \textbf{rectangle} (rectangular box) $R$ in $\R^n$ is the cartesian product of intervals:

    \[R = \Pi_{i=1}^n [a_i,b_i] = [a_1,b_1] \times [a_2,b_2] \times \cdots \times [a_b, b_n],\]
    
    where $a_i < b_i$ for all $i = 1,2,\dots,n$.

    The $n$-dimensional volume $v\of{R}$ of $R$ is

    \[v\of{R} = \Pi_{i=1}^n (b_i - a_i) = (b_1 - a_1) \dots (b_n - a_n).\]
\end{definition}

\begin{definition}[a partition]
    Let $R$ be a rectangle in $\R^n$. By a \textbf{partition} of $R$, we mean a finite collection $\cal{P}$ of subrectangles of $R$ such that $\bigcup_{P \in \cal{P}}P = R$ and $R_1 \cap R_2 = \emptyset$ whenever $R_1, R_2 \in \cal{P}$ and $R_1 \neq R_2$.

    The mesh (or norm) of of the partition $\cal{P}$ is the number $\norm{\cal{P}} = \max\set{\diam\of{P}: P \in \cal{P}}$ where $\diam\of{P} = \max\set{\norm{x-y}: x,y \in P}$ is the diameter of $P$ (if $P = \Pi_{i=1}^n (\alpha_i, \beta_i)$, then $\diam\of{P} = \sqrt{\sum_{i=1}^{n} (\beta_i - \alpha_i)^2}$)
\end{definition}

\begin{definition}[a refinement]
    Let $\cal{P}$ and $\cal{Q}$ be partitions of a rectangle $R \subseteq \R^n$. We say that $\cal{Q}$ is a refinement of $\cal{P}$ (or is finer than $\cal{P}$) if for all $Q \in \cal{Q}$, there exists a $P \in \cal{P}$ such that $Q \subseteq P$.
\end{definition}

\begin{lemma}
    Let $\cal{P}$ and $\cal{Q}$ be partitions of a rectangle $R$. Then 
    \begin{enumerate}
        \item $\cal{Q}$ is a refinement of $\cal{P}$ if and only if each $P \in \cal{P}$ is the union of those $Q \in \cal{Q}$ that are contained in $P$.
        \item There exists a partition $\cal{T}$ of $R$ which refines both $\cal{P}$ and $\cal{Q}$ (e.g., $\cal{T} = \set{P \cap Q: P \in \cal{P}, Q \in \cal{Q}, \text{ and } P \cap Q \text{ is a rectangle.}}$)
    \end{enumerate}
\end{lemma}

\begin{lemma}
    If $\cal{P}$ is a partition of a rectangle $R \subseteq \R^n$, then $v\of{R} = \sum_{P \in \cal{P}} v\of{P}$.
\end{lemma}